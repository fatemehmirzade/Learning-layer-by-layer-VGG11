# Learning-layer-by-layer-VGG11
The implementation of the VGG11 network on the CIFAR10 dataset underscores the foundational focus of this endeavor. The overarching objective entails the meticulous design of the VGG11 architecture and subsequent training through two distinct learning paradigms: end-to-end learning and layer-wise learning. Particularly, the latter method aims to dissect the nuanced influence of diverse parameters within the network structure.

Integral to this pursuit is the comprehensive analysis and reporting of critical metrics throughout the training process. Notably, the code meticulously tracks and presents the accuracy and loss curves, alongside the evaluation of training data, throughout the course of end-to-end learning. Moreover, in the context of layer-wise learning, the code meticulously scrutinizes the accuracy and evaluation metrics post each layer's training completion. Additionally, the final performance of the network on test data, leveraging the optimal iteration of the trained model, is meticulously evaluated and documented.

Furthermore, the code ventures into the realm of intrinsic network characteristics, delineating the architectural prowess and distinctive traits of the VGG11 model. As a deep convolutional neural network (CNN) model, VGG11 epitomizes the culmination of seminal research efforts by the Visual Geometry Group at the University of Oxford. Renowned for its uniform architecture, VGG11 manifests through an intricate ensemble of convolutional layers, pooling layers, and fully connected layers, each meticulously orchestrated to preserve spatial resolution and glean essential features.

Indeed, VGG11's simplicity belies its profound efficacy, evidenced by its resounding success across diverse image classification tasks. However, this success is not without its computational demands, with the network's depth and parameter complexity necessitating substantial computational resources for training. Nonetheless, VGG11 stands as a beacon of innovation within the landscape of CNN architectures, emblematic of the pivotal role played by depth in augmenting performance within image recognition tasks.

Data augmentation methods used in the code: 
![image](https://github.com/fmirzadeh99/Learning-layer-by-layer-VGG11/assets/169579231/4e2f4545-c8bd-4bbe-82f6-4739923b9c81)


Hyperparameters used in the network:
![image](https://github.com/fmirzadeh99/Learning-layer-by-layer-VGG11/assets/169579231/69622bd1-6f81-4a71-b7dc-83232b611165)

Results:
![image](https://github.com/fmirzadeh99/Learning-layer-by-layer-VGG11/assets/169579231/ad181e0f-ec51-4652-a725-ca344af1d9c2)


![image](https://github.com/fmirzadeh99/Learning-layer-by-layer-VGG11/assets/169579231/f25b1b97-161d-42a1-a1a9-7ee0afd87694)


![image](https://github.com/fmirzadeh99/Learning-layer-by-layer-VGG11/assets/169579231/dcf33900-bcc5-4eea-8652-87c100efe2a8)

